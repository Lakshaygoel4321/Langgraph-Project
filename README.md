# LangGraph Multi-Agent Chat System

A production-ready, full-stack AI application built with **LangGraph**, **FastAPI**, and **Next.js**.  
The system orchestrates specialized **business**, **research**, and **technical** agents with:

- Multi-step reasoning and routing
- Web searchâ€“augmented synthesis
- Conversation memory using a checkpointer
- Streaming and non-streaming responses
- Clean, modular architecture suitable for real-world projects

---

## Features

- **Multi-Agent Architecture**
  - Supervisor agent routes questions to **business**, **research**, or **technical** specialists.
  - Synthesis agents combine LLM output with web search for more reliable answers.
  - Validator agent scores answer quality (0â€“10) before returning to the user.

- **Memory & Threading**
  - Conversation-level memory using LangGraph checkpointer.
  - `thread_id` support to maintain separate chat sessions.
  - Ability to retrieve state and history per thread.

- **Full-Stack Implementation**
  - **Backend**: FastAPI + LangGraph + Groq LLM + Tavily search.
  - **Frontend**: Next.js (App Router), TypeScript, Tailwind CSS.
  - Streaming via Server-Sent Events (SSE) for incremental UI updates.

- **Production-Ready Design**
  - Clear separation of concerns (agents, synthesis, validators, routers, graph, config).
  - Environment-based configuration.
  - CORS, logging, and basic security headers.
  - `.gitignore` tuned for Python + Node.js monorepo.

---

## Architecture & Workflow

The system implements a **multi-agent orchestration pattern** with intelligent routing and synthesis capabilities.

<p align="center">
  <img src="./workflow-diagram.png" alt="LangGraph Multi-Agent Workflow Architecture" width="700"/>
</p>

### Workflow Steps

1. **Start** â†’ User submits a question via the Next.js frontend
2. **Supervisor Agent** â†’ Analyzes and classifies the question as:
   - ğŸ¢ **Business** (strategy, finance, marketing, management)
   - ğŸ”¬ **Research** (academic, scientific, theoretical)
   - ğŸ’» **Technical** (programming, engineering, system design)
3. **Domain Agent** â†’ Specialized agent generates initial response
4. **Synthesis Agent** â†’ Enhances answer by merging:
   - LLM-generated insights (Groq - Llama 3.3 70B)
   - Real-time web search results (Tavily)
5. **Validator Agent** â†’ Quality assurance and confidence scoring (0-10)
6. **End** â†’ Returns structured response with answer, classification, and confidence

### Agent Responsibilities

| Agent | Domain | Example Questions |
|-------|--------|------------------|
| ğŸ¢ **Business Agent** | Strategy, Finance, Operations, Marketing | "What is SWOT analysis?", "How to conduct market research?", "Explain startup funding" |
| ğŸ”¬ **Research Agent** | Academic, Scientific, Theoretical | "Explain quantum computing", "What is the scientific method?", "Climate change research" |
| ğŸ’» **Technical Agent** | Programming, Engineering, System Design | "Write a Python sorting algorithm", "Explain REST APIs", "Design a microservice" |

---

## Tech Stack

### Backend

- **Language**: Python 3.10+
- **Framework**: FastAPI
- **Orchestration**: LangGraph
- **LLM Provider**: Groq (e.g., `llama-3.3-70b-versatile`)
- **Search**: Tavily
- **HTTP Server**: Uvicorn

### Frontend

- **Framework**: Next.js 15+ (App Router, TypeScript)
- **UI**: React 18, Tailwind CSS
- **HTTP Client**: Axios + Fetch (for SSE)
- **Icons & UI Enhancements**: `lucide-react`, `react-markdown`

---

## Project Structure

```
Langgraph-Project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ agent.py        # FastAPI endpoints (ask, stream, history, state, status)
â”‚   â”‚   â””â”€â”€ middleware.py       # Logging, CORS, security headers
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py         # Environment & configuration management
â”‚   â”‚   â””â”€â”€ prompts.py          # System prompts (supervisor, agents, synthesis, validator)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agents/             # Business, research, technical agents
â”‚   â”‚   â”‚   â”œâ”€â”€ base_agent.py   # Base agent class
â”‚   â”‚   â”‚   â”œâ”€â”€ business_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ research_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ technical_agent.py
â”‚   â”‚   â”œâ”€â”€ synthesis/          # Synthesis agents & base class
â”‚   â”‚   â”‚   â”œâ”€â”€ base_synthesis.py
â”‚   â”‚   â”‚   â””â”€â”€ synthesis_agents.py
â”‚   â”‚   â”œâ”€â”€ validators/         # Validator agent for quality assurance
â”‚   â”‚   â”‚   â””â”€â”€ validator.py
â”‚   â”‚   â”œâ”€â”€ routers/            # Supervisor & routing logic
â”‚   â”‚   â”‚   â””â”€â”€ supervisor.py
â”‚   â”‚   â”œâ”€â”€ utils/              # State, schemas, tools (Tavily search)
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py        # LangGraph state definition
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py      # Pydantic models
â”‚   â”‚   â”‚   â””â”€â”€ tools.py        # External API integrations
â”‚   â”‚   â””â”€â”€ graph/
â”‚   â”‚       â””â”€â”€ workflow.py     # LangGraph StateGraph construction & memory
â”‚   â”œâ”€â”€ .env                    # Backend environment (not committed)
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ main.py                 # FastAPI entrypoint
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx        # Main chat interface page
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx      # Root layout with metadata
â”‚   â”‚   â”‚   â””â”€â”€ globals.css     # Global styles & Tailwind
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx   # Main chat component
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.tsx     # Message rendering with markdown
â”‚   â”‚   â”‚   â””â”€â”€ InputForm.tsx       # User input form (if separated)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts          # API client (ask, stream, history, state)
â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚       â””â”€â”€ index.ts        # Shared TypeScript interfaces
â”‚   â”œâ”€â”€ public/                 # Static assets
â”‚   â”œâ”€â”€ package.json            # Node.js dependencies
â”‚   â”œâ”€â”€ tsconfig.json           # TypeScript configuration
â”‚   â”œâ”€â”€ tailwind.config.js      # Tailwind CSS configuration
â”‚   â”œâ”€â”€ postcss.config.js       # PostCSS configuration
â”‚   â”œâ”€â”€ next.config.js          # Next.js configuration
â”‚   â””â”€â”€ .env.local              # Frontend environment (not committed)
â”œâ”€â”€ workflow-diagram.png        # Architecture visualization
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ LICENSE                     # MIT License
â””â”€â”€ README.md                   # This file
```

---

## Prerequisites

- **Python** 3.10+
- **Node.js** 18+
- **Git**
- API keys for:
  - [**Groq**](https://console.groq.com/) (LLM)
  - [**Tavily**](https://tavily.com/) (Web search)

---

## Backend Setup (FastAPI + LangGraph)

### 1. Navigate to backend

```
cd backend
```

### 2. Create & activate virtual environment

```
# Windows (PowerShell)
python -m venv .venv
.\.venv\Scripts\Activate

# Linux / macOS
python -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies

```
pip install -r requirements.txt
```

### 4. Configure environment variables

Create `.env` in `backend/`:

```
GROQ_API_KEY=your_groq_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

### 5. Run backend server

```
python main.py
```

**Backend will be available at:**

- ğŸŒ API Root: `http://localhost:8000/`
- âœ… Health Check: `http://localhost:8000/health`
- ğŸ¤– Agent Endpoint: `POST http://localhost:8000/api/v1/ask`
- ğŸ“š API Docs: `http://localhost:8000/docs` (Swagger UI)

---

## Frontend Setup (Next.js)

### 1. Navigate to frontend

```
cd frontend
```

### 2. Install dependencies

```
npm install
# or
yarn install
```

### 3. Configure frontend environment

Create `.env.local` in `frontend/`:

```
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### 4. Run Next.js dev server

```
npm run dev
# or
yarn dev
```

**Frontend will be available at:**

- ğŸ–¥ï¸ Application: `http://localhost:3000/`

---

## How It Works

### Request Flow

1. **User Input** â†’ User enters a question in the Next.js chat interface
2. **API Call** â†’ Frontend sends `POST /api/v1/ask` (or `/ask/stream` for streaming)
3. **Workflow Execution** â†’ FastAPI passes question + `thread_id` to LangGraph `AgentWorkflow`
4. **Agent Pipeline**:
   - **SupervisorAgent** â†’ Classifies question (business / research / technical)
   - **Domain Agent** â†’ Generates specialized response based on classification
   - **Synthesis Agent** â†’ Merges LLM output with Tavily web search results
   - **ValidatorAgent** â†’ Scores answer quality and confidence (0â€“10)
5. **Response** â†’ Structured JSON returned with answer, classification, reasoning, and confidence
6. **UI Update** â†’ Frontend displays formatted response with metadata badges

### Memory & Conversation Threading

- Each conversation maintains context using a unique `thread_id` (stored in browser session storage)
- **LangGraph MemorySaver** checkpointer persists state across multiple turns
- **Conversation History**: Access via `GET /api/v1/history/{thread_id}`
- **State Inspection**: Debug current state via `GET /api/v1/state/{thread_id}`

---

## API Endpoints

### `POST /api/v1/ask`

Submit a question (non-streaming mode).

**Request:**

```
{
  "question": "What is SWOT analysis, and how is it used in strategic planning?",
  "thread_id": "thread-123-abc",
  "stream": false
}
```

**Response:**

```
{
  "question": "What is SWOT analysis, and how is it used in strategic planning?",
  "answer": "SWOT analysis is a strategic planning framework used to evaluate...",
  "confidence_score": "9",
  "classifier": "business",
  "reasoning": "The question relates to business strategy and management frameworks.",
  "timestamp": "2025-12-25T12:00:00Z",
  "thread_id": "thread-123-abc"
}
```

### `POST /api/v1/ask/stream`

Submit a question with **Server-Sent Events (SSE)** streaming.

Returns incremental updates as the workflow progresses through each agent node.

### `GET /api/v1/history/{thread_id}`

Retrieve conversation history for a specific thread.

**Response:**

```
{
  "thread_id": "thread-123-abc",
  "messages": [
    {
      "question": "What is SWOT analysis?",
      "answer": "...",
      "classifier": "business",
      "confidence": "9"
    }
  ],
  "total_interactions": 5
}
```

### `GET /api/v1/state/{thread_id}`

Get current LangGraph state snapshot for debugging.

### `GET /api/v1/status`

Service health and metadata.

**Response:**

```
{
  "status": "operational",
  "model": "llama-3.3-70b-versatile",
  "available_agents": ["business", "research", "technical"],
  "features": {
    "streaming": true,
    "synthesis": true,
    "validation": true,
    "memory": true,
    "checkpointer": "MemorySaver"
  }
}
```

---

## Development Workflow

### Backend Development

- **Modify Prompts**: Edit `backend/config/prompts.py` to tune agent behavior
- **Add New Agents**: Extend `backend/src/agents/` with new specialized agents
- **Adjust Routing**: Update `backend/src/routers/supervisor.py` for classification logic
- **Graph Configuration**: Modify `backend/src/graph/workflow.py` for workflow changes

### Frontend Development

- **UI Components**: Edit `frontend/src/components/` for interface changes
- **API Integration**: Update `frontend/src/services/api.ts` for new endpoints
- **Styling**: Customize `frontend/src/app/globals.css` and `tailwind.config.js`
- **Types**: Maintain `frontend/src/types/index.ts` for type safety

---

## Testing

### Backend Tests

```
cd backend
pytest tests/
# or
python -m pytest tests/ -v
```

### Frontend Tests

```
cd frontend
npm run test
# or
yarn test
```

Create test files in:
- Backend: `backend/tests/`
- Frontend: `frontend/__tests__/` or `frontend/src/__tests__/`

---

## Deployment

### Backend Deployment

**Option 1: Docker**

```
# Dockerfile (backend)
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Option 2: Traditional Server**

```
# Install dependencies
pip install -r requirements.txt

# Run with production server
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Frontend Deployment

**Option 1: Vercel** (Recommended for Next.js)

```
npm install -g vercel
vercel
```

**Option 2: Self-hosted**

```
cd frontend
npm run build
npm run start
# Or use PM2
pm2 start npm --name "langgraph-frontend" -- start
```

**Production Environment Variables:**

```
# Backend
GROQ_API_KEY=your_production_key
TAVILY_API_KEY=your_production_key

# Frontend
NEXT_PUBLIC_API_URL=https://api.yourdomain.com
```

---

## Roadmap & Future Enhancements

- [ ] **Authentication** - JWT-based user authentication and authorization
- [ ] **Vector Database RAG** - Integrate PostgreSQL + pgvector or Pinecor for document retrieval
- [ ] **Multi-Thread UI** - Visual chat history sidebar with thread management
- [ ] **Specialized Agents** - Add finance, legal, marketing, and healthcare agents
- [ ] **Analytics Dashboard** - Usage metrics, agent performance tracking
- [ ] **Voice Interface** - Speech-to-text input and text-to-speech output
- [ ] **File Upload Support** - Document analysis and Q&A over uploaded files
- [ ] **Collaborative Features** - Share conversations and multi-user sessions
- [ ] **Model Flexibility** - Support for multiple LLM providers (OpenAI, Anthropic, etc.)
- [ ] **Advanced Memory** - Long-term memory with semantic search

---

## Contributing

We welcome contributions! Here's how to get started:

1. **Fork** the repository
2. **Create** a feature branch:
   ```
   git checkout -b feature/add-new-agent
   ```
3. **Make** your changes with clear, descriptive commits
4. **Test** your changes thoroughly
5. **Submit** a Pull Request with:
   - Clear description of changes
   - Why the change is beneficial
   - How to test the new feature

### Contribution Guidelines

- Follow existing code style and structure
- Add tests for new features
- Update documentation as needed
- Keep commits atomic and well-described

---

## Troubleshooting

### Common Issues

**Backend won't start:**
- Check Python version: `python --version` (need 3.10+)
- Verify API keys are set in `.env`
- Check port 8000 is not in use: `netstat -ano | findstr :8000`

**Frontend build errors:**
- Clear cache: `rm -rf .next node_modules` then `npm install`
- Check Node version: `node --version` (need 18+)
- Verify `tsconfig.json` path aliases are correct

**Memory not working:**
- Ensure `thread_id` is being passed consistently
- Check LangGraph checkpointer is initialized in `workflow.py`

---

## License

This project is licensed under the **MIT License** - see the [LICENSE](./LICENSE) file for details.

You are free to use, modify, and distribute this software with proper attribution.

---

## Acknowledgments

Built with:
- [LangGraph](https://github.com/langchain-ai/langgraph) - Multi-agent orchestration framework
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [Next.js](https://nextjs.org/) - React framework for production
- [Groq](https://groq.com/) - Fast LLM inference
- [Tavily](https://tavily.com/) - AI-powered web search

---

## Contact & Support

- **Repository**: [github.com/Lakshaygoel4321/Langgraph-Multiagent-Chat](https://github.com/Lakshaygoel4321/Langgraph-Multiagent-Chat)
- **Issues**: [Report bugs or request features](https://github.com/Lakshaygoel4321/Langgraph-Multiagent-Chat/issues)
- **Discussions**: [Join the conversation](https://github.com/Lakshaygoel4321/Langgraph-Multiagent-Chat/discussions)

---

<p align="center">
  Made with â¤ï¸ by developers, for developers
</p>

<p align="center">
  <strong>â­ Star this repo if you find it helpful!</strong>
</p>
```
